services:
  db:
    image: mysql:8.0
    container_name: redmine-db
    restart: always
    environment:
      MYSQL_DATABASE: redmine_db
      MYSQL_USER: redmine
      MYSQL_PASSWORD: enter_password
      MYSQL_ROOT_PASSWORD: Enter_Password!
    volumes:
      - mysql_data:/var/lib/mysql
    networks: [ai_net]

  redmine:
    build:
      context: ./redmine
      dockerfile: Dockerfile
    container_name: redmine-app
    restart: always
    ports:
      - "3000:3000"
    depends_on:
      - db
    environment:
      BUNDLE_FORCE_RUBY_PLATFORM: true
      REDMINE_HOST: m2cbook.local
      REDMINE_HTTPS: true
      REDMINE_DB_MYSQL: db
      REDMINE_DB_PORT: 3306
      REDMINE_DB_DATABASE: redmine_db
      REDMINE_DB_USERNAME: redmine
      REDMINE_DB_PASSWORD: enter_password
      RAILS_SECRET_KEY_BASE: "RUN rails secret      OR     openssl rand -hex 64    to GENERAT"
      SECRET_KEY_BASE: "RUN rails secret      OR     openssl rand -hex 64    to GENERAT"
    volumes:
      - redmine_data:/usr/src/redmine/files
      - ./redmine/config/database.yml:/usr/src/redmine/config/database.yml
      - ./redmine/plugins:/usr/src/redmine/plugins
      - ./redmine/themes:/usr/src/redmine/public/themes
      - ./redmine/redmine-init.sh:/usr/local/bin/redmine-init.sh
    networks: [ai_net]
    entrypoint: ["/usr/local/bin/redmine-init.sh"]
    command: ["rails", "server", "-b", "0.0.0.0", "-p", "3000"]

  n8n:
    build:
      context: ./n8n
      dockerfile: Dockerfile
    container_name: n8n
    restart: always
    ports:
      - "5678:5678"  # Internal only; external SSL handled by Apache
    environment:
      - N8N_CUSTOM_EXTENSIONS=/data/packages
      - N8N_HOST=n8n.codemusic.ca
      - N8N_PROTOCOL=http  # NOTE: Apache terminates SSL
      - N8N_PORT=5678
      - N8N_WEBHOOK_URL=https://n8n.codemusic.ca/
      - WEBHOOK_URL=https://n8n.codemusic.ca/
      - WEBHOOK_TUNNEL_URL=https://n8n.codemusic.ca/
      - MORTY_SIGN_KEY=q9ofLSY/cc96sOWKqpttFYEfHBD8nhxIun/NfOon2qA=
      - TAVILY_API_KEY=tvly-dev-insert-key
    volumes:
      - n8n_data:/home/node/.n8n
      - ./n8n/plugins:/data/packages
    networks: [ai_net]
    
  comfyui:
    build:
      context: ./comfyui
      dockerfile: Dockerfile.comfyui
    platform: linux/arm64
    container_name: musai_comfyui
    restart: always
    ports:
      - "8008:8188"    # host:container
    volumes:
      # official tree lives under /root/ComfyUI
      - ./ai-model-cache/comfyui-models:/root/ComfyUI/models
      - ./ai-model-cache/comfyui-output:/root/ComfyUI/output
      - ./ai-model-cache/comfyui-input:/root/ComfyUI/input
    networks: [ai_net]

  musai:
    build:
      context: ./musai
      dockerfile: Dockerfile
    container_name: musai
    restart: always
    ports:
      - "5680:80"  # Only for internal routing; Apache will reverse-proxy
    environment:
      - VITE_BASE_PATH=/
      - VITE_N8N_WEBHOOK_URL=https://n8n.codemusic.ca/webhook/
      - VITE_WELCOME_MESSAGE=Welcome to Musai
      - VITE_SITE_TITLE=Musai
      - VITE_N8N_WEBHOOK_USERNAME=codemusai
      - VITE_N8N_WEBHOOK_SECRET=R0V3RBY73
      - VITE_ASSISTANT_NAME=Musai
      - VITE_RIDDLE_GATE_MODE=preview
    networks: [ai_net]

  musai-api:
    build: ./musai-api
    container_name: musai-api
    restart: unless-stopped
    ports:
      - "9000:9000"
    environment:
      VOICES_DIR: /voices
      WHISPER_MODELS_DIR: /whisper-models
      FASTER_WHISPER_MODEL: base.en
      DEFAULT_PIPER_VOICE: en_US-GlaDOS-medium
      OLLAMA_BASE_URL: http://host.docker.internal:11434
      OLLAMA_MODEL: llama3
    volumes:
      - ./ai-model-cache/piper-voices:/voices:ro
      - ./ai-model-cache/whisper-models:/whisper-models
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks: [ai_net]

      # LLM passthrough (optional)
      OLLAMA_BASE_URL: http://host.docker.internal:11434
      OLLAMA_MODEL: llama3
    volumes:
      - ./ai-model-cache/piper-voices:/voices:ro
      - ./ai-model-cache/whisper-models:/whisper-models:ro
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      ai_net:
        aliases: [ musai-api ]

  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    restart: unless-stopped
    ports:
      - "8080:8080"
#    environment:
#      - BASE_URL=https://search.codemusic.ca
#      - SECRET_KEY=b618b27c029ee157f5e30a12d1067d8566d715009b3873d1e5ca634ceea1dfd6
#      - INSTANCE_NAME=MusaiSearch
#      - SEARXNG_BIND_ADDRESS=0.0.0.0:8080
#      - AUTOCOMPLETE=duckduckgo
#      - MORTY_URL=http://morty:3000/
#      - MORTY_KEY=q9ofLSY/cc96sOWKqpttFYEfHBD8nhxIun/NfOon2qA=
    depends_on: [morty]
    networks: [ai_net]
    volumes: 
      # Config (single file)
      - ./searxng/settings.yml:/etc/searxng/settings.yml

      # Brand & static overrides (whole folders)
      - ./searxng/branding/img:/usr/local/searxng/searx/static/themes/simple/img:ro
      - ./searxng/static/css:/usr/local/searxng/searx/static/themes/simple/css:ro
      - ./searxng/static/js:/usr/local/searxng/searx/static/themes/simple/js:ro

      # Template overrides (optional, if you copied them)
      - ./searxng/templates/simple:/usr/local/searxng/searx/templates/simple:ro

    healthcheck:
      test: ["CMD", "wget", "-qO", "-", "http://localhost:8080/search?q=ping&format=json"]
      interval: 30s
      timeout: 5s
      retries: 5

  morty:
    image: dalf/morty:latest
    container_name: morty
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - MORTY_KEY=q9ofLSY/cc96sOWKqpttFYEfHBD8nhxIun/NfOon2qA=
      - MORTY_ADDRESS=0.0.0.0:3000
      - DEBUG=true
    networks: [ai_net]
    healthcheck:
      test: ["CMD", "wget", "-qO", "-", "http://localhost:3000/morty/https/example.com/"]
      interval: 30s
      timeout: 5s
      retries: 5

  wyoming-whisper:
    image: rhasspy/wyoming-whisper
    restart: unless-stopped
    command: --model base.en --language en --uri tcp://0.0.0.0:10300
    ports: ["10300:10300"]
    networks:
      ai_net:
        aliases: [wyoming-whisper]

  wyoming-piper:
    image: rhasspy/wyoming-piper
    restart: unless-stopped
    # use your local GLaDOS model files (the pair .onnx + .json must exist in ./ai-model-cache/piper-voices)
    volumes:
      - ./ai-model-cache/piper-voices:/voices
    command: >
      --model  /voices/en_US-GlaDOS-medium.onnx
      --config /voices/en_US-GlaDOS-medium.onnx.json
      --uri    tcp://0.0.0.0:10200
    ports: ["10200:10200"]
    networks:
      ai_net:
        aliases: [wyoming-piper]

  silverbullet:
    build:
      context: .
      dockerfile: silverbullet/Dockerfile
    container_name: rovervault
    restart: unless-stopped
    ports:
      - "3030:3000"
    volumes:
      - ./silverbullet/data/notes:/space
      - ./silverbullet/PLUGINS/silverbullet-ai:/space/PLUGINS/silverbullet-ai
      - ./silverbullet/SECRETS:/space/SECRETS
      - ./silverbullet/SETTINGS:/space/SETTINGS
    environment:
      - BASE_URL=http://localhost:3030
      - SB_USER=admin:EnterPasswordHere!!
    networks: [ai_net]

  homeassistant:
    image: ghcr.io/home-assistant/home-assistant:stable
    container_name: homeassistant
    restart: unless-stopped
    ports:
      - "8123:8123"  # Keep private; access via VPN or n8n
    volumes: #Use a local folder unique to this environment:
      - ./homeassist-configs/dev-config:/config #Macbook
#  - ./homeassist-configs/staging-config:/config #iMac
#  - ./homeassist-configs/prod-config:/config #Pi5
      - /etc/localtime:/etc/localtime:ro
    networks: [ai_net]

volumes:
  mysql_data:
  redmine_data:
  n8n_data:

networks:
  ai_net:
    driver: bridge 